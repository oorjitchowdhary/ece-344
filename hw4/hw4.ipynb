{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pRUhg9XfF_g"
   },
   "source": [
    "# Homework 4: Character-level prediction with RNNs\n",
    "\n",
    "**By:** Oorjit Chowdhary\n",
    "\n",
    "In this homework, you will train a recurrent neural network to predict the next English character, using a small corpus of works from Shakespeare. This notebook will walk you through the different steps required to accomplish this.\n",
    "\n",
    "**Deliverable**: You should submit the completed version of this Jupyter notebook to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GrZJq8Sd_Oxf"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAupL-ecg0ta"
   },
   "source": [
    "The function `load_shakespeare_corpus()` below downloads the corpus into a local text file, and reads the contents into a string variable called `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oQ9kVtr61Xz9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakespeare.txt already exists.\n",
      "Data loaded. Vocabulary size: 39\n"
     ]
    }
   ],
   "source": [
    "# Part 1: load the tiny shakespeare corpus\n",
    "\n",
    "def load_shakespeare_corpus():\n",
    "  url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "  path = Path(\"tinyshakespeare.txt\")\n",
    "\n",
    "  # Download the file if it doesn't exist\n",
    "  if not path.exists():\n",
    "    print(\"Downloading tinyshakespeare.txt...\")\n",
    "    urllib.request.urlretrieve(url, path)\n",
    "    print(\"Download complete.\")\n",
    "  else:\n",
    "    print(f\"{path} already exists.\")\n",
    "\n",
    "  # Read and process the text\n",
    "  text = path.read_text(encoding=\"utf-8\").lower()\n",
    "  return text\n",
    "\n",
    "text = load_shakespeare_corpus()\n",
    "\n",
    "print(f\"Data loaded. Vocabulary size: {len(set(text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_SDbJ5Sg9J0"
   },
   "source": [
    "Below, we create a `Vocab` class that stores all distinct tokens (characters and some minimal punctuation) encountered in the corpus and creates a token-to-integer mapping. We will use that mapping later to convert text to numerical inputs for the RNN that we will train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VjSAQJA4lVmV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "def isolate_chars_and_punctuation(text: str) -> str:\n",
    "    \"\"\"Isolate characters and punctuation.\"\"\"\n",
    "    return re.sub(\"[^A-Za-z']+\", \" \", text).lower()\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Turn text into a Python list of tokens.\"\"\"\n",
    "    return list(isolate_chars_and_punctuation(text))\n",
    "\n",
    "\n",
    "class Vocab(object):\n",
    "    \"\"\"Vocabulary for text.\n",
    "\n",
    "    Taken from Dive into Deep Learning: https://d2l.ai/chapter_recurrent-neural-networks/text-sequence.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        # Flatten a 2D list if needed\n",
    "        if tokens and isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # Count token frequencies\n",
    "        counter = Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.idx_to_token = list(\n",
    "            sorted(\n",
    "                set(\n",
    "                    [\"<unk>\"]\n",
    "                    + reserved_tokens\n",
    "                    + [token for token, freq in self.token_freqs if freq >= min_freq]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if hasattr(indices, \"__len__\") and len(indices) > 1:\n",
    "            return [self.idx_to_token[int(index)] for index in indices]\n",
    "        return self.idx_to_token[indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return self.token_to_idx[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NF3YIrAzl0m2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " '<unk>': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vocabulary based on the current text.\n",
    "vocab = Vocab(tokenize(text))\n",
    "\n",
    "# The vocabulary will ignore punctuation other than spaces and \"'\".\n",
    "vocab.token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l9k-hKAhpcF"
   },
   "source": [
    "The example below shows how to use the `vocab` object to convert a string of characters to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t0rJ7iXchvyZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 10, 7, 0, 19, 23, 11, 5, 13, 0, 8, 17, 26]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_string = \"the quick fox\"\n",
    "\n",
    "# tokenize first\n",
    "example_tokens = tokenize(example_string)\n",
    "\n",
    "# apply the vocab to the tokenized version.\n",
    "# NOTE: we use slicing notation instead of parentheses.\n",
    "vocab[example_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kLcKHLskkile"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in the dataset: 1115394\n",
      "Unique characters (vocab size): 29\n",
      "\n",
      "--- Data Snippet (first 80 chars) ---\n",
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect the Data\n",
    "print(f\"Total characters in the dataset: {len(text)}\")\n",
    "print(f\"Unique characters (vocab size): {len(vocab)}\")\n",
    "print(\"\\n--- Data Snippet (first 80 chars) ---\")\n",
    "print(text[:80])\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DbW-3LYiGIN"
   },
   "source": [
    "In the cell below, we create hyperparameters used throughout our model definition and training. These include the size of the hidden state maintained by the RNN, the number of training epochs and learning rate, the length of input sequences and predictions, and the number of steps per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R5ArQ9m4f-9N"
   },
   "outputs": [],
   "source": [
    "# 2. Hyperparameters\n",
    "hidden_size = 64\n",
    "learning_rate = 0.005\n",
    "num_epochs = 100\n",
    "sequence_length = 32\n",
    "steps_per_epoch = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5TA8ZcfiI_g"
   },
   "source": [
    "## Part 1: creating the dataset\n",
    "\n",
    "Below, we will create a character prediction dataset. To do so, we will create a subclass of the `torch.utils.data.Dataset` class whose `__getitem__` method provides pairs of text sequences of equal length which are one character apart in the original corpus.\n",
    "\n",
    "To demonstrate, suppose that the corpus is a single sentence:\n",
    "\n",
    "```\n",
    "the quick brown fox jumps over the lazy dog\n",
    "```\n",
    "\n",
    "and suppose that we set `seq_len = 3` in the constructor of `CharPredictionDataset`. Then, calling the `__getitem__` method with argument `index=4` should access the following pair of character sequences:\n",
    "\n",
    "```\n",
    "(\"qui\", \"uic\")\n",
    "```\n",
    "\n",
    "and map them to the corresponding one-hot encoding, as provided by the `to_one_hot_sequence` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PlTnbTOwgA4H"
   },
   "outputs": [],
   "source": [
    "# Create the tensor dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "# One-hot encoding function\n",
    "def to_one_hot_sequence(indices: List[int], vocab: Vocab) -> torch.Tensor:\n",
    "    \"\"\"Converts a list of indices into a one-hot tensor.\n",
    "\n",
    "    Args:\n",
    "        indices (List[int]): List of indices.\n",
    "        vocab (Vocab): A vocabulary object.\n",
    "    \"\"\"\n",
    "    # Convert indices to tensors and perform One-Hot encoding.\n",
    "    indices_tensor = torch.tensor(indices, dtype=torch.long)\n",
    "    return one_hot(indices_tensor, num_classes=len(vocab)).float()\n",
    "\n",
    "\n",
    "class CharPredictionDataset(Dataset):\n",
    "    \"\"\"Custom dataset for character prediction.\n",
    "\n",
    "    Attributes:\n",
    "      data: The corpus text.\n",
    "      seq_len: The length of each sequence in the dataset.\n",
    "      vocab: A vocabulary object providing the token-to-integer mapping.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: str, seq_len: int, vocab: Vocab):\n",
    "      self.text = data\n",
    "      self.seq_len = seq_len\n",
    "      self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "      # Calculate the effective length of the dataset\n",
    "      # We need seq_len characters for input and seq_len characters for output\n",
    "      # So we need at least seq_len + seq_len characters, but output starts at index 1\n",
    "      return len(self.text) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      # Construct the input and target sequences\n",
    "      # 1. Determine the start and end positions of the slice\n",
    "      start = index\n",
    "      end = index + self.seq_len\n",
    "      \n",
    "      # Input sequence: characters from start to end\n",
    "      input_text = self.text[start:end]\n",
    "      # Target sequence: characters from start+1 to end+1 (shifted by 1)\n",
    "      target_text = self.text[start + 1:end + 1]\n",
    "      \n",
    "      # 2. Process the text using the tokenize function\n",
    "      input_tokens = tokenize(input_text)\n",
    "      target_tokens = tokenize(target_text)\n",
    "      \n",
    "      # 3. Convert the tokens to indices using vocab\n",
    "      input_indices = self.vocab[input_tokens]\n",
    "      target_indices = self.vocab[target_tokens]\n",
    "      \n",
    "      # 4. Convert to tensors using to_one_hot_sequence\n",
    "      input_seq = to_one_hot_sequence(input_indices, self.vocab)\n",
    "      target_seq = to_one_hot_sequence(target_indices, self.vocab)\n",
    "      \n",
    "      return input_seq, target_seq\n",
    "\n",
    "\n",
    "dataset = CharPredictionDataset(isolate_chars_and_punctuation(text), seq_len=sequence_length, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset length: 40\n",
      "Input sequence shape: torch.Size([3, 28])\n",
      "Target sequence shape: torch.Size([3, 28])\n",
      "Input characters: qui\n",
      "Target characters: uic\n"
     ]
    }
   ],
   "source": [
    "test_corpus = \"the quick brown fox jumps over the lazy dog\"\n",
    "test_vocab = Vocab(tokenize(test_corpus))\n",
    "test_dataset = CharPredictionDataset(isolate_chars_and_punctuation(test_corpus), seq_len=3, vocab=test_vocab)\n",
    "\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")\n",
    "input_seq, target_seq = test_dataset[4]\n",
    "print(f\"Input sequence shape: {input_seq.shape}\")\n",
    "print(f\"Target sequence shape: {target_seq.shape}\")\n",
    "\n",
    "input_indices = torch.argmax(input_seq, dim=1).tolist()\n",
    "target_indices = torch.argmax(target_seq, dim=1).tolist()\n",
    "\n",
    "input_chars = test_vocab.to_tokens(input_indices)\n",
    "target_chars = test_vocab.to_tokens(target_indices)\n",
    "\n",
    "print(f\"Input characters: {''.join(input_chars)}\")\n",
    "print(f\"Target characters: {''.join(target_chars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ00u8yXkDFY"
   },
   "source": [
    "## Part 2: creating the model\n",
    "\n",
    "Below, we define the character-level RNN model. Your task is to complete the missing neural network blocks (the fields currently set as `None` in the constructor) and the `forward` method, according to the following specification:\n",
    "\n",
    "- the `rnn` block should be a RNN block expecting inputs of size `input_size`, maintaining a hidden state of size `hidden_size`.\n",
    "- the `fc` block should be a fully connected linear layer mapping inputs of size `hidden_size` to outputs of size `vocab_size`.\n",
    "- the `softmax` block should apply the softmax function to the last dimension of the output of the fully connected linear layer.\n",
    "\n",
    "**Note**: your `.forward()` method implementation should expect inputs of size $(N, L, V)$, where $N$ is the batch size, $L$ is the sequence length, and $S$ is the dimension of the one-hot encoding (equal to the size of the vocabulary), and return outputs of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xjtApiCUgDv_"
   },
   "outputs": [],
   "source": [
    "# 3. Model Definition\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, vocab_size: int):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # Complete the definitions below\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        # hidden shape: (batch_size, 1, hidden_size)\n",
    "\n",
    "        # Forward Propagation\n",
    "\n",
    "        # 1. Pass x into the RNN layer\n",
    "        # Note: The RNN returns two values: (output, hidden), we only need the output\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        \n",
    "        # 2. Pass the RNN output into the fully connected layer\n",
    "        # rnn_out shape: (batch_size, seq_len, hidden_size)\n",
    "        fc_out = self.fc(rnn_out)\n",
    "        \n",
    "        # 3. Apply Softmax to the result and return\n",
    "        # fc_out shape: (batch_size, seq_len, vocab_size)\n",
    "        output = self.softmax(fc_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2REsBY1slpbJ"
   },
   "source": [
    "Below, we create the RNN model and use the Adam optimizer (a variant of stochastic gradient descent) to minimize the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m8z9fo3zgFf-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Device: mps\n",
      "CharRNN(\n",
      "  (rnn): RNN(29, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=29, bias=True)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Accelerate training using GPU if available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# 4. Initialize Model, Loss, and Optimizer\n",
    "model = CharRNN(len(vocab), hidden_size, len(vocab)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wg5ags62vNBT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 32, 29])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_loader = DataLoader(dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
    "\n",
    "inp, outp = next(iter(text_loader))\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgLkJ1mpl8YR"
   },
   "source": [
    "## Part 3: training loop\n",
    "\n",
    "Complete the training loop below, using the model and dataloader defined in the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YdZJ4nP9gGzU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [09:16<1:24:01, 56.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/100], Average Loss: 2.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [18:37<1:14:32, 55.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [20/100], Average Loss: 2.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [27:46<1:03:42, 54.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [30/100], Average Loss: 2.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [36:56<53:56, 53.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [40/100], Average Loss: 2.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [46:11<46:32, 55.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [50/100], Average Loss: 2.9658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [55:33<37:24, 56.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [60/100], Average Loss: 2.9647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [1:04:02<25:16, 50.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [70/100], Average Loss: 2.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [1:12:28<16:42, 50.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [80/100], Average Loss: 2.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [1:21:02<08:37, 51.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [90/100], Average Loss: 2.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:29:39<00:00, 53.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [100/100], Average Loss: 2.9606\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 6. Training Loop\n",
    "print(\"Starting training...\")\n",
    "all_losses = []  # To store average loss per epoch\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # Load a minibatch from dataloader\n",
    "    for input_seq, target_seq in text_loader:\n",
    "        # Move data to device (MPS/GPU)\n",
    "        input_seq = input_seq.to(device)\n",
    "        target_seq = target_seq.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(input_seq)\n",
    "        \n",
    "        # Convert target from one-hot to class indices\n",
    "        target_indices = torch.argmax(target_seq, dim=-1)\n",
    "        \n",
    "        # Reshape output: (batch_size * seq_len, vocab_size)\n",
    "        output_flat = output.view(-1, len(vocab))\n",
    "        # Reshape target: (batch_size * seq_len)\n",
    "        target_flat = target_indices.view(-1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output_flat, target_flat)\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(text_loader)\n",
    "    all_losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"\\nEpoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpzEfni6mCOf"
   },
   "source": [
    "## Part 4: plotting perplexity per epoch\n",
    "\n",
    "In Lecture 13, we defined perplexity as the exponential of the average cross-entropy loss. Plot the perplexity by epoch below.\n",
    "\n",
    "**Note**: recall that the cross-entropy losses calculated during training are stored in `all_losses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ywlBWmSkkraA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Calculate the perplexity and plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Calculate perplexity from losses (perplexity = exp(loss))\n",
    "perplexities = [np.exp(loss) for loss in all_losses]\n",
    "\n",
    "# Plot perplexity over epochs\n",
    "plt.plot(range(1, num_epochs + 1), perplexities, linewidth=2)\n",
    "\n",
    "plt.title(\"Perplexity per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity (over minibatch)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsGqqT9gmeXR"
   },
   "source": [
    "Finally, in the last two cells we create a prediction function that predicts the next few characters given a partial sentence. You can run it to examine the predictions generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AvkKmnpXgKmR"
   },
   "outputs": [],
   "source": [
    "# 6. Prediction Function\n",
    "def predict_completion(prefix: str, max_new_chars: int = 32):\n",
    "    \"\"\"Generate text completions using the trained character-level RNN and vocabulary.\"\"\"\n",
    "    cleaned_prefix = isolate_chars_and_punctuation(prefix).strip().lower()\n",
    "    if not cleaned_prefix:\n",
    "        print(\"Error: Prefix cannot be empty after cleaning.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Input: '{cleaned_prefix}'\")\n",
    "\n",
    "    tokens = tokenize(cleaned_prefix)\n",
    "    if not tokens:\n",
    "        print(\"Error: Prefix does not contain valid characters.\")\n",
    "        return\n",
    "\n",
    "    unknown_chars = [ch for ch in tokens if ch not in vocab.token_to_idx]\n",
    "    if unknown_chars:\n",
    "        print(f\"Warning: Unknown characters {set(unknown_chars)} will be mapped to <unk>.\")\n",
    "\n",
    "    indices = [vocab[token] for token in tokens]\n",
    "    completion_tokens = tokens.copy()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    def one_hot_batch(idx: int) -> torch.Tensor:\n",
    "        return to_one_hot_sequence([idx], vocab).unsqueeze(0).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = torch.zeros(1, 1, model.hidden_size, device=device)\n",
    "\n",
    "        # Warm up hidden state with all but the last token of the prefix\n",
    "        for idx in indices[:-1]:\n",
    "            step_input = one_hot_batch(idx)\n",
    "            _, hidden = model.rnn(step_input, hidden)\n",
    "\n",
    "        current_idx = indices[-1]\n",
    "\n",
    "        for _ in range(max_new_chars):\n",
    "            step_input = one_hot_batch(current_idx)\n",
    "            out, hidden = model.rnn(step_input, hidden)\n",
    "            logits = model.fc(out)\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "            next_idx = torch.argmax(probs, dim=-1).item()\n",
    "            next_token = vocab.idx_to_token[next_idx]\n",
    "\n",
    "            completion_tokens.append(next_token)\n",
    "            current_idx = next_idx\n",
    "\n",
    "            if next_token in {\" \", \"\\n\"}:\n",
    "                break\n",
    "\n",
    "    prediction = \"\".join(completion_tokens)\n",
    "    print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nTQJmB_4gURh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'appl'\n",
      "Prediction: apple \n",
      "--------------------\n",
      "Input: 'th'\n",
      "Prediction: the \n",
      "--------------------\n",
      "Input: 'lov'\n",
      "Prediction: love \n",
      "--------------------\n",
      "Input: 'ki'\n",
      "Prediction: kind \n"
     ]
    }
   ],
   "source": [
    "# 7. Run Predictions\n",
    "predict_completion('appl')\n",
    "print(\"-\" * 20)\n",
    "predict_completion('th')\n",
    "print(\"-\" * 20)\n",
    "predict_completion('lov')\n",
    "print(\"-\" * 20)\n",
    "predict_completion('ki')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10IB1-7m335s52SWBqtHS_L5cmuQqkCK9",
     "timestamp": 1763357090981
    },
    {
     "file_id": "1rkKOjjcvG8kjKcQv0RRINnBKIclIAnGU",
     "timestamp": 1763356744812
    },
    {
     "file_id": "1KhduwppjT8oH4HG0vFb_FLDsbAyBXwLs",
     "timestamp": 1763344347153
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
